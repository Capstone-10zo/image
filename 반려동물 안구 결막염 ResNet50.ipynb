{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNLEQFbR+2cFUnTljabMv0F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 구글 드라이브 import"],"metadata":{"id":"IVDQmcminRns"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOSJpq_5sxhg","executionInfo":{"status":"ok","timestamp":1712828356104,"user_tz":-540,"elapsed":17072,"user":{"displayName":"Pengrid","userId":"01639413828201057168"}},"outputId":"3ed397c3-84f3-46a7-b400-faa55a72ee9c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["# colab에서 이미지데이터 압축해제"],"metadata":{"id":"2W-1Q-6jnYhW"}},{"cell_type":"code","source":["#%cd /content/gdrive/MyDrive/세종대수업자료/캡스톤/train\n","#!unzip -qq \"/content/gdrive/MyDrive/세종대수업자료/캡스톤/153.반려동물 안구질환 데이터/01.데이터/1.Training/라벨링데이터/TL1.zip\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rNK2mDjjXZX","outputId":"2bf977d4-f238-4b34-f7ab-77a104b08b06"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/세종대수업자료/캡스톤/train\n","replace 개/안구/안구초음파/백내장/무/crop_D0_99ac3014-63a6-11ec-b317-0a7404972c70.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}]},{"cell_type":"code","source":["#%cd /content/gdrive/MyDrive/세종대수업자료/캡스톤/train\n","#!unzip -qq \"/content/gdrive/MyDrive/세종대수업자료/캡스톤/153.반려동물 안구질환 데이터/01.데이터/1.Training/라벨링데이터/TL2.zip\""],"metadata":{"id":"X6gOh5weWnLV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#%cd /content/gdrive/MyDrive/세종대수업자료/캡스톤/val\n","#!unzip -qq \"/content/gdrive/MyDrive/세종대수업자료/캡스톤/153.반려동물 안구질환 데이터/01.데이터/2.Validation/라벨링데이터/VL.zip\""],"metadata":{"id":"rpqAFiViu8D4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"HP0qWYU-7PZ6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712828360221,"user_tz":-540,"elapsed":4121,"user":{"displayName":"Pengrid","userId":"01639413828201057168"}},"outputId":"7d199625-e85a-4f2f-c51e-740c5094720f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"SLQXdXACP8K0","executionInfo":{"status":"ok","timestamp":1712828386590,"user_tz":-540,"elapsed":362,"user":{"displayName":"Pengrid","userId":"01639413828201057168"}}},"outputs":[],"source":["#-*- coding:utf-8 -*-\n","import matplotlib.pyplot as plt #모형 학습시 accuracy와 loss를 저장하기 위한 라이브러리입니다.\n","\n","\"\"\"시드 고정을 위한 라이브러리\"\"\"\n","import random\n","import numpy as np\n","\n","\"\"\"전처리를 위한 라이브러리\"\"\"\n","import os\n","import pandas as pd\n","\n","\"\"\"Keras 라이브러리\"\"\"\n","import tensorflow.keras as keras #keras 라이브러리입니다.\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator #이미지 데이터를 tensor로 변한하기 위해 활용되는 라이브러리입니다.\n","from tensorflow.keras.layers import Dense #학습 모형을 구축하기 위해 활용되는 라이브러리입니다.\n","from tensorflow.keras import Sequential #학습 모형을 구축하기 위해 활용되는 라이브러리 입니다.\n","\n","from tensorflow.keras.applications.resnet import ResNet50, ResNet101, ResNet152\n","from tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\n","from tensorflow.keras.applications.densenet import DenseNet121, DenseNet169, DenseNet201\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n","from tensorflow.keras.applications.efficientnet import EfficientNetB0\n","# from tensorflow.keras.utils import multi_gpu_model\n","#from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","\n","val_path = '/content/gdrive/MyDrive/세종대수업자료/캡스톤/결막염val/'\n","\n","seed = 2\n","\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","class Import_data:\n","    def __init__(self, train_path):\n","        self.train_path = train_path\n","        self.test_path = val_path\n","\n","    def train(self):\n","        train_datagen = ImageDataGenerator(rescale=1. / 255,\n","                                           featurewise_std_normalization=True,\n","                                           zoom_range=0.2,\n","                                           channel_shift_range=0.1,\n","                                           rotation_range=20,\n","                                           width_shift_range=0.2,\n","                                           height_shift_range=0.2,\n","                                           horizontal_flip=True\n","                                           )\n","        train_generator = train_datagen.flow_from_directory(\n","            self.train_path,\n","            target_size=(224, 224),\n","            batch_size=8\n","        )\n","        val_generator = train_datagen.flow_from_directory(\n","            self.test_path,\n","            target_size=(224, 224),\n","            batch_size=8\n","        )\n","\n","        return train_generator, val_generator\n","\n","\n","def densenet_121():\n","    network = DenseNet121(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                          pooling='avg')\n","    return network\n","\n","\n","class Load_model:\n","    def __init__(self, train_path, model_name):\n","        self.num_class = len(os.listdir(train_path))\n","        self.model_name = model_name\n","\n","    def resnet_v1_50(self):\n","        network = ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                           pooling='avg')\n","        return network\n","\n","    def resnet_v1_101(self):\n","        network = ResNet101(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                            pooling='avg')\n","        return network\n","\n","    def resnet_v1_152(self):\n","        network = ResNet152(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                            pooling='avg')\n","        return network\n","\n","    def resnet_v2_50(self):\n","        network = ResNet50V2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                             pooling='avg')\n","        return network\n","\n","    def resnet_v2_101(self):\n","        network = ResNet101V2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                              pooling='avg')\n","        return network\n","\n","    def resnet_v2_152(self):\n","        network = ResNet152V2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                              pooling='avg')\n","        return network\n","\n","    def densenet_169(self):\n","        network = DenseNet169(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                              pooling='avg')\n","        return network\n","\n","    def densenet_201(self):\n","        network = DenseNet201(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                              pooling='avg')\n","        return network\n","\n","    def inception_v3(self):\n","        network = InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                              pooling='avg')\n","        return network\n","\n","    def inception_v4(self):\n","        network = InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                                    pooling='avg')\n","        return network\n","\n","    def efficientnet(self):\n","        network = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3),\n","                                 pooling='avg')\n","        return network\n","\n","\n","    def build_network(self):\n","        if self.model_name == 'resnet_v1_50':\n","            network = self.resnet_v1_50()\n","        elif self.model_name == 'resnet_v1_101':\n","            network = self.resnet_v1_101()\n","        elif self.model_name == 'resnet_v1_152':\n","            network = self.resnet_v1_152()\n","        elif self.model_name == 'resnet_v2_50':\n","            network = self.resnet_v2_50()\n","        elif self.model_name == 'resnet_v2_101':\n","            network = self.resnet_v2_101()\n","        elif self.model_name == 'resnet_v2_152':\n","            network = self.resnet_v2_152()\n","        elif self.model_name == 'densenet_121':\n","            network = densenet_121()\n","        elif self.model_name == 'densenet_169':\n","            network = self.densenet_169()\n","        elif self.model_name == 'densenet_201':\n","            network = self.densenet_201()\n","        elif self.model_name == 'inception_v3':\n","            network = self.inception_v3()\n","        elif self.model_name == 'inception_v4':\n","            network = self.inception_v4()\n","        elif self.model_name == 'efficientnet':\n","            network = self.efficientnet()\n","\n","        model = Sequential()\n","        model.add(network)\n","        model.add(Dense(2048, activation='relu'))\n","        model.add(Dense(self.num_class, activation='softmax'))\n","        model.summary()\n","\n","        return model\n","\n","class Fine_tunning:\n","    def __init__(self, train_path, model_name, epoch, multi_gpu=0):\n","        self.data = Import_data(train_path)\n","        self.train_data, self.val_data = self.data.train()\n","        self.load_model = Load_model(train_path, model_name)\n","        self.multi_gpu = multi_gpu\n","        self.epoch = epoch\n","        self.model_name = model_name\n","        self.train_path = train_path\n","\n","    def training(self):\n","        data_name = self.train_path.split('/')\n","        data_name = data_name[len(data_name)-2]\n","        optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.999, nesterov=True)\n","        model = self.load_model.build_network()\n","        save_folder = './model_saved/' + data_name + '/' + self.model_name + '_' + str(self.epoch) + '/'\n","        if not os.path.exists(save_folder):\n","            os.makedirs(save_folder)\n","        check_point = ModelCheckpoint(save_folder + 'model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', verbose=1,\n","                                      monitor='val_acc', save_best_only=True, mode='auto')\n","        if self.multi_gpu == 0:\n","            model.compile(loss='categorical_crossentropy',\n","                          optimizer=optimizer,\n","                          metrics=['acc'])\n","            history = model.fit(\n","                self.train_data,\n","                steps_per_epoch=self.train_data.samples / self.train_data.batch_size,\n","                epochs=self.epoch,\n","                validation_data=self.val_data,\n","                validation_steps=self.val_data.samples / self.val_data.batch_size,\n","                callbacks=[check_point],\n","                verbose=1)\n","        else:\n","            with tf.device('/cpu:0'):\n","                cpu_model = model\n","            model = multi_gpu_model(cpu_model, gpus=self.multi_gpu)\n","            model.summary()\n","            model.compile(loss='categorical_crossentropy',\n","                          optimizer=optimizer,\n","                          metrics=['acc'])\n","            history = model.fit(\n","                self.train_data,\n","                steps_per_epoch=self.train_data.samples / self.train_data.batch_size,\n","                epochs=self.epoch,\n","                validation_data=self.val_data,\n","                validation_steps=self.val_data.samples / self.val_data.batch_size,\n","                callbacks=[check_point],\n","                verbose=1)\n","        return history\n","\n","    def save_accuracy(self, history):\n","        data_name = self.train_path.split('/')\n","        data_name = data_name[len(data_name)-2]\n","        save_folder = './model_saved/' + data_name + '/' + self.model_name + '_' + str(self.epoch) + '/'\n","        acc = history.history['acc']\n","        val_acc = history.history['val_acc']\n","        loss = history.history['loss']\n","        val_loss = history.history['val_loss']\n","        epochs = range(len(acc))\n","        epoch_list = list(epochs)\n","\n","        df = pd.DataFrame({'epoch': epoch_list, 'train_accuracy': acc, 'validation_accuracy': val_acc},\n","                          columns=['epoch', 'train_accuracy', 'validation_accuracy'])\n","        df_save_path = save_folder + 'accuracy.csv'\n","        df.to_csv(df_save_path, index=False, encoding='euc-kr')\n","\n","        plt.plot(epochs, acc, 'b', label='Training acc')\n","        plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","        plt.title('Training and validation accuracy')\n","        plt.legend()\n","        save_path = save_folder + 'accuracy.png'\n","        plt.savefig(save_path)\n","        plt.cla()\n","\n","        plt.plot(epochs, loss, 'b', label='Training loss')\n","        plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","        plt.title('Training and validation loss')\n","        plt.legend()\n","        save_path = save_folder + 'loss.png'\n","        plt.savefig(save_path)\n","        plt.cla()\n","\n","        name_list = os.listdir(save_folder)\n","        h5_list = []\n","        for name in name_list:\n","            if '.h5' in name:\n","                h5_list.append(name)\n","        h5_list.sort()\n","        h5_list = [save_folder + name for name in h5_list]\n","        for path in h5_list[:len(h5_list) - 1]:\n","            os.remove(path)\n","        K.clear_session()\n"]},{"cell_type":"code","source":["train_path = '/content/gdrive/MyDrive/세종대수업자료/캡스톤/결막염/' #경로 마지막에 반드시 '/'를 기입해야합니다.\n","model_name = 'resnet_v1_50'\n","epoch = 30\n","\n","if __name__ == '__main__':\n","    fine_tunning = Fine_tunning(train_path=train_path,\n","                                model_name=model_name,\n","                                epoch=epoch)\n","    history = fine_tunning.training()\n","    fine_tunning.save_accuracy(history)\n"],"metadata":{"id":"Uch_mPT4TBZ6","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1712831117211,"user_tz":-540,"elapsed":2728836,"user":{"displayName":"Pengrid","userId":"01639413828201057168"}},"outputId":"b81c508f-a46e-47f7-eb80-b8b7413781fe"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1460: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Found 1922 images belonging to 2 classes.\n","Found 481 images belonging to 2 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 0s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 2048)              23587712  \n","                                                                 \n"," dense (Dense)               (None, 2048)              4196352   \n","                                                                 \n"," dense_1 (Dense)             (None, 2)                 4098      \n","                                                                 \n","=================================================================\n","Total params: 27788162 (106.00 MB)\n","Trainable params: 27735042 (105.80 MB)\n","Non-trainable params: 53120 (207.50 KB)\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1862: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py:1872: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","241/240 [==============================] - ETA: -1s - loss: 0.3500 - acc: 0.8959\n","Epoch 1: val_acc improved from -inf to 0.50104, saving model to ./model_saved/결막염/resnet_v1_50_30/model-001-0.895942-0.501040.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r240/240 [==============================] - 714s 3s/step - loss: 0.3500 - acc: 0.8959 - val_loss: 4899.9209 - val_acc: 0.5010\n","Epoch 2/30\n","241/240 [==============================] - ETA: 0s - loss: 0.4683 - acc: 0.8855\n","Epoch 2: val_acc did not improve from 0.50104\n","240/240 [==============================] - 56s 235ms/step - loss: 0.4683 - acc: 0.8855 - val_loss: 5259.5239 - val_acc: 0.4990\n","Epoch 3/30\n","241/240 [==============================] - ETA: 0s - loss: 0.3085 - acc: 0.9048\n","Epoch 3: val_acc did not improve from 0.50104\n","240/240 [==============================] - 55s 230ms/step - loss: 0.3085 - acc: 0.9048 - val_loss: 58.8057 - val_acc: 0.5010\n","Epoch 4/30\n","241/240 [==============================] - ETA: 0s - loss: 0.3105 - acc: 0.9001\n","Epoch 4: val_acc improved from 0.50104 to 0.58420, saving model to ./model_saved/결막염/resnet_v1_50_30/model-004-0.900104-0.584200.h5\n","240/240 [==============================] - 56s 232ms/step - loss: 0.3105 - acc: 0.9001 - val_loss: 6.7093 - val_acc: 0.5842\n","Epoch 5/30\n","241/240 [==============================] - ETA: 0s - loss: 0.2870 - acc: 0.9173\n","Epoch 5: val_acc improved from 0.58420 to 0.70062, saving model to ./model_saved/결막염/resnet_v1_50_30/model-005-0.917274-0.700624.h5\n","240/240 [==============================] - 56s 232ms/step - loss: 0.2870 - acc: 0.9173 - val_loss: 5.3835 - val_acc: 0.7006\n","Epoch 6/30\n","241/240 [==============================] - ETA: 0s - loss: 0.3128 - acc: 0.8985\n","Epoch 6: val_acc did not improve from 0.70062\n","240/240 [==============================] - 55s 227ms/step - loss: 0.3128 - acc: 0.8985 - val_loss: 3.6850 - val_acc: 0.5489\n","Epoch 7/30\n","241/240 [==============================] - ETA: 0s - loss: 0.2084 - acc: 0.9329\n","Epoch 7: val_acc improved from 0.70062 to 0.92931, saving model to ./model_saved/결막염/resnet_v1_50_30/model-007-0.932882-0.929314.h5\n","240/240 [==============================] - 56s 233ms/step - loss: 0.2084 - acc: 0.9329 - val_loss: 0.3408 - val_acc: 0.9293\n","Epoch 8/30\n","241/240 [==============================] - ETA: 0s - loss: 0.2092 - acc: 0.9251\n","Epoch 8: val_acc improved from 0.92931 to 0.94387, saving model to ./model_saved/결막염/resnet_v1_50_30/model-008-0.925078-0.943867.h5\n","240/240 [==============================] - 55s 230ms/step - loss: 0.2092 - acc: 0.9251 - val_loss: 0.3191 - val_acc: 0.9439\n","Epoch 9/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1624 - acc: 0.9428\n","Epoch 9: val_acc did not improve from 0.94387\n","240/240 [==============================] - 56s 228ms/step - loss: 0.1624 - acc: 0.9428 - val_loss: 0.3082 - val_acc: 0.9418\n","Epoch 10/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1452 - acc: 0.9506\n","Epoch 10: val_acc improved from 0.94387 to 0.95842, saving model to ./model_saved/결막염/resnet_v1_50_30/model-010-0.950572-0.958420.h5\n","240/240 [==============================] - 56s 231ms/step - loss: 0.1452 - acc: 0.9506 - val_loss: 0.1195 - val_acc: 0.9584\n","Epoch 11/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1313 - acc: 0.9495\n","Epoch 11: val_acc improved from 0.95842 to 0.97089, saving model to ./model_saved/결막염/resnet_v1_50_30/model-011-0.949532-0.970894.h5\n","240/240 [==============================] - 55s 230ms/step - loss: 0.1313 - acc: 0.9495 - val_loss: 0.1041 - val_acc: 0.9709\n","Epoch 12/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1495 - acc: 0.9448\n","Epoch 12: val_acc did not improve from 0.97089\n","240/240 [==============================] - 54s 227ms/step - loss: 0.1495 - acc: 0.9448 - val_loss: 0.1539 - val_acc: 0.9418\n","Epoch 13/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1220 - acc: 0.9631\n","Epoch 13: val_acc did not improve from 0.97089\n","240/240 [==============================] - 55s 227ms/step - loss: 0.1220 - acc: 0.9631 - val_loss: 0.1294 - val_acc: 0.9709\n","Epoch 14/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1054 - acc: 0.9625\n","Epoch 14: val_acc improved from 0.97089 to 0.97921, saving model to ./model_saved/결막염/resnet_v1_50_30/model-014-0.962539-0.979210.h5\n","240/240 [==============================] - 55s 227ms/step - loss: 0.1054 - acc: 0.9625 - val_loss: 0.0640 - val_acc: 0.9792\n","Epoch 15/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1252 - acc: 0.9589\n","Epoch 15: val_acc did not improve from 0.97921\n","240/240 [==============================] - 54s 224ms/step - loss: 0.1252 - acc: 0.9589 - val_loss: 0.0827 - val_acc: 0.9771\n","Epoch 16/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1347 - acc: 0.9438\n","Epoch 16: val_acc did not improve from 0.97921\n","240/240 [==============================] - 54s 224ms/step - loss: 0.1347 - acc: 0.9438 - val_loss: 0.1286 - val_acc: 0.9563\n","Epoch 17/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1083 - acc: 0.9615\n","Epoch 17: val_acc did not improve from 0.97921\n","240/240 [==============================] - 54s 225ms/step - loss: 0.1083 - acc: 0.9615 - val_loss: 0.1106 - val_acc: 0.9584\n","Epoch 18/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1290 - acc: 0.9558\n","Epoch 18: val_acc did not improve from 0.97921\n","240/240 [==============================] - 56s 231ms/step - loss: 0.1290 - acc: 0.9558 - val_loss: 0.1467 - val_acc: 0.9584\n","Epoch 19/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1290 - acc: 0.9485\n","Epoch 19: val_acc did not improve from 0.97921\n","240/240 [==============================] - 55s 227ms/step - loss: 0.1290 - acc: 0.9485 - val_loss: 0.0783 - val_acc: 0.9626\n","Epoch 20/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1297 - acc: 0.9558\n","Epoch 20: val_acc did not improve from 0.97921\n","240/240 [==============================] - 54s 225ms/step - loss: 0.1297 - acc: 0.9558 - val_loss: 0.0997 - val_acc: 0.9584\n","Epoch 21/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1304 - acc: 0.9594\n","Epoch 21: val_acc did not improve from 0.97921\n","240/240 [==============================] - 54s 225ms/step - loss: 0.1304 - acc: 0.9594 - val_loss: 0.1293 - val_acc: 0.9709\n","Epoch 22/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1319 - acc: 0.9620\n","Epoch 22: val_acc did not improve from 0.97921\n","240/240 [==============================] - 55s 228ms/step - loss: 0.1319 - acc: 0.9620 - val_loss: 0.2037 - val_acc: 0.9563\n","Epoch 23/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1224 - acc: 0.9641\n","Epoch 23: val_acc did not improve from 0.97921\n","240/240 [==============================] - 55s 230ms/step - loss: 0.1224 - acc: 0.9641 - val_loss: 0.0654 - val_acc: 0.9709\n","Epoch 24/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1081 - acc: 0.9651\n","Epoch 24: val_acc did not improve from 0.97921\n","240/240 [==============================] - 56s 234ms/step - loss: 0.1081 - acc: 0.9651 - val_loss: 0.0622 - val_acc: 0.9771\n","Epoch 25/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1069 - acc: 0.9610\n","Epoch 25: val_acc did not improve from 0.97921\n","240/240 [==============================] - 56s 231ms/step - loss: 0.1069 - acc: 0.9610 - val_loss: 0.1568 - val_acc: 0.9148\n","Epoch 26/30\n","241/240 [==============================] - ETA: 0s - loss: 0.0790 - acc: 0.9729\n","Epoch 26: val_acc did not improve from 0.97921\n","240/240 [==============================] - 57s 236ms/step - loss: 0.0790 - acc: 0.9729 - val_loss: 0.0574 - val_acc: 0.9730\n","Epoch 27/30\n","241/240 [==============================] - ETA: 0s - loss: 0.0747 - acc: 0.9714\n","Epoch 27: val_acc did not improve from 0.97921\n","240/240 [==============================] - 57s 236ms/step - loss: 0.0747 - acc: 0.9714 - val_loss: 0.0934 - val_acc: 0.9688\n","Epoch 28/30\n","241/240 [==============================] - ETA: 0s - loss: 0.0881 - acc: 0.9646\n","Epoch 28: val_acc did not improve from 0.97921\n","240/240 [==============================] - 56s 234ms/step - loss: 0.0881 - acc: 0.9646 - val_loss: 0.0809 - val_acc: 0.9709\n","Epoch 29/30\n","241/240 [==============================] - ETA: 0s - loss: 0.0780 - acc: 0.9719\n","Epoch 29: val_acc did not improve from 0.97921\n","240/240 [==============================] - 55s 230ms/step - loss: 0.0780 - acc: 0.9719 - val_loss: 0.0593 - val_acc: 0.9730\n","Epoch 30/30\n","241/240 [==============================] - ETA: 0s - loss: 0.1011 - acc: 0.9615\n","Epoch 30: val_acc did not improve from 0.97921\n","240/240 [==============================] - 55s 229ms/step - loss: 0.1011 - acc: 0.9615 - val_loss: 0.0678 - val_acc: 0.9709\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn import metrics\n","\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# modelPath = './model_saved/train/efficientnet_200/'  # 모델이 저장된 경로\n","modelPath = '/content/model_saved/일반/resnet_v1_50_10/'  # 모델이 저장된 경로\n","weight = 'model-007-0.557414-0.580312.h5'        # 학습된 모델의 파일이름\n","test_Path = '/content/gdrive/MyDrive/세종대수업자료/캡스톤/val/개/안구/일반/결막염' # 테스트 이미지 폴더\n","\n","model = load_model(modelPath + weight)\n","datagen_test = ImageDataGenerator(rescale=1./255)\n","generator_test = datagen_test.flow_from_directory(directory=test_Path,\n","                                                  target_size=(224, 224),\n","                                                  batch_size=256,\n","                                                  shuffle=False)\n","\n","# model로 test set 추론\n","generator_test.reset()\n","cls_test = generator_test.classes\n","cls_pred = model.predict(generator_test, verbose=1, workers=0)\n","cls_pred_argmax = cls_pred.argmax(axis=1)\n","\n","# 결과 산출 및 저장\n","report = metrics.classification_report(y_true=cls_test, y_pred=cls_pred_argmax, output_dict=True)\n","report = pd.DataFrame(report).transpose()\n","report.to_csv(f'/content/output/report_test_{weight[:-3]}.csv', index=True, encoding='cp949')\n","print(report)"],"metadata":{"id":"r0x8Tof8ZaJq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712253314875,"user_tz":-540,"elapsed":103338,"user":{"displayName":"Pengrid","userId":"01639413828201057168"}},"outputId":"c05d10ef-0229-4325-9d62-086b0b40614c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8909 images belonging to 9 classes.\n","35/35 [==============================] - 93s 2s/step\n","              precision    recall  f1-score      support\n","0              0.356979  0.454432  0.399854  2403.000000\n","1              0.720638  0.664090  0.691209  2587.000000\n","2              0.708598  0.714785  0.711678  3436.000000\n","3              0.000000  0.000000  0.000000   469.000000\n","7              0.000000  0.000000  0.000000    14.000000\n","accuracy       0.591088  0.591088  0.591088     0.591088\n","macro avg      0.357243  0.366661  0.360548  8909.000000\n","weighted avg   0.578836  0.591088  0.583043  8909.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"m4I3EpvKuUeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YhQ5pl3yuUcJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LWJ8tJ_auUZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3vkvKmZauUXZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WVH-UYQ6uUVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DKyrn-iGuUS0"},"execution_count":null,"outputs":[]}]}